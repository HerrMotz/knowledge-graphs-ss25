# Week 2 — Create KG from Tabular Data

You will need an OpenAI API Key to run the code. Store it in the environment variable `OPENAI_API_KEY` or change the
code to pass it to the client when instantiating it.

## The Pipeline

The new pipeline works as follows:
1. Extract ingredients from the tabular data using a large language model, to get rid of irrelevant information. [create_batch.py](create_batch.py), [upload_batch.py](upload_batch.py), [get_batch_results.py](get_batch_results.py)
2. Create a hierarchical clustering of the ingredients. Similar ingredients should be put into the same category, e.g. "tomato" and "sun-dried tomato".
3. Map the ingredients to my Ontology or Wikidata.
   1. The ontology has existing ingredients. Again override the mapping to the entities from within the ontology
          using `KNOWN_INGREDIENTS`
   2. Add these ingredients (hierarchy: use ontology ingredients → use wikidata items → create canonical ingredient
      in the ontology)
4. Map cities to the mentioned locations in the dataset.
5. Lastly, integrate the tabular data with the ontology, by creating pizza places, pizzas and ingredients.
6. Write the results to [pizza_data.ttl](pizza_data.ttl)

## Commands for the Pipeline
### Ingredients

1. Run

```shell
python3 create_batch.py
```

2. Run

```shell
python3 upload_batch.py
```

3. Run

```shell
python3 get_batch_results.py
```  

4. Run

```shell
python3 clean_llm_results.py
```

5. Fill the [locked_qid_map.json](locked_qid_map.json) with expert knowledge
6. Run

```shell
python3 ingredient_QID_mapping.py 
```

7. Run

```shell
python3 create_ingredients.jsonl.py
```

### Cities

1. Fill the [locked_city_qid_map.json](locked_city_qid_map.json) with "expert" knowledge
2. Run

```shell
python3 city_qid_mapping.py
```

### Integrate Data from CSV-file with Ontology

```shell
python3 integrate_tabular_data_with_ontology.py 
```

## File Purposes

| File name                                            | Purpose                                                                                                                                                         |
|------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [results_k.json](results_k.json)                     | The ingredient extraction step output from the LLM                                                                                                              |
| [data.csv](data.csv)                                 | The dataset given from the task                                                                                                                                 |
| [ingredient_qid_map.json](ingredient_qid_map.json)   | Defines the mapping from normalised ingredient name to a Wikidata item, generated by [ingredient_QID_mapping.py](ingredient_QID_mapping.py)                     |
| [locked_qid_map.json](locked_qid_map.json)           | Contains manual mappings for ingredients to a Wikidata item                                                                                                     |
| [city_qid_map.json](city_qid_map.json)               | In analogy to ingredient_qid_map, it defines the mapping from city name to a Wikidata item, gen'd by [city_qid_mapping.py](city_qid_mapping.py)                 |
| [locked_city_qid_map.json](locked_city_qid_map.json) | Same as [locked_qid_map.json](locked_qid_map.json), but now for cities                                                                                          |
| [ingredients.jsonl](ingredients.jsonl)               | Generated by [create_ingredients.jsonl.py](create_ingredients.jsonl.py) from a [results.json](results.json) (the output from the LMM ingredient extraction step |
| [pizza_data.ttl](pizza_data.ttl)                     | The results of the integration step, containing the pizza places, pizzas and ingredients, as well as the prices and addresses                                   |

## Possible improvements

+ It is obvious that the ontology is in German and the data is English, and it would be nice to unify them
  We made an informed decision to keep them different, to show that they can be integrated, even though different
  languages were used. Furthermore, we could use this for other cases, were different, but equivalently legitimate
  terminology was used.
+ Based on the name of the menu item, the ontological category could be identified and an assumption about
  the ingredients could be made, e.g. the name is "Pizza Margherita", then the ontological category "Pizza Margherita"
  could inferred by lexicographic matching, adding the category's characteristic ingredients.
+ Add place categories to Pizzeria, like "Burger Place", "University", ...
+ The list of KNOWN_INGREDIENTS should only contain ingredients which are not present in Wikidata.
  Furthermore, it would be even better to add the missing ingredients to Wikidata, instead of
  defining them in our ontology. But this script's purpose it to show what can be done, not the real deal.
+ The ingredients could be further categorised, e.g. "sun-dried tomatoes", "cherry tomatoes" and "tomato basil sauce"
  could be subsumed in a class "tomato ingredients". The same applies to "fried egg". If the goal is to keep the
  querying simple, one could add the class itself as an ingredient assertion.
+ We could, instead of creating our own ontology, use `schema.org` for any assertion.
+ The LLM extraction step can be improved with more prompt engineering
+ The LLM cleaning step can be improved with classical NLP methods, e.g. the word
  stems or singulars could be used as normalised names or for matching a Wikidata item

```turtle
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix ex: <http://example.org/> .
@prefix schema: <http://schema.org/> .

ex:Store1 a schema:FoodEstablishment ;
    schema:hasMenuItem ex:MenuItem1 .

ex:MenuItem1 a schema:MenuItem ;
    schema:name "Cheeseburger" ;
    schema:price "5.99"^^xsd:decimal ;
    schema:priceCurrency "USD" .
```